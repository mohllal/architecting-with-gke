# Module 2: Logging and Monitoring

- Stackdriver is a suite of multi-cloud resource reconnaissance tools that includes *monitoring*, *logging*, and *debugging* for the applications and infrastructure.
- ***Stackdriver logging*** can serve as a ***log repository and aggregator***. The logs can be searched with the power of BigQuery which simplify some of the most complex searches. Stackdriver logging is the ***native logging solution*** for many GCP products and services. It offers agent-based installation software for computer engine instances and Amazon EC2 instances.
- ***Stackdriver monitoring*** allows creating custom dashboards and alerts with metrics that represent the health of the application. Stackdriver dashboards and graphs provide an at-a-glance method to ensure that systems are operating properly.
- ***Stackdriver metric is a value that can be monitored such as CPU or disk usage***, these can be values that change up or down over time called gauge values or values that increase over time called counters. ***Stackdriver Events are things that happen to the cluster pod or container***. Here are a few examples of events. The restart of a pod, node or service, scaling up or down of the number of deployments in the cluster or an application responding to a request. ***Events typically report success, warning, or failure while metrics report numerical values***.
- ***Stackdriver Trace allows quantifying the true latency for each of the requests made by the components in an application*** and the stacked line charts can help in visualizing detecting bottlenecks.
- ***Stackdriver Error Reporting notices when an error occurs within an application, captures the error information and call stack, and then provide certain information for debugging***.
- ***Stackdriver Debugger is a real-time analysis tool that allows to walk through the code and set watch points to determine the value of key variables during code execution***.
- ***Stackdriver saves the container logs for 30 days*** although the log data may not be immediately available.
- ***The basic GKE logs such as the system component logs, standard output and the standard error messages are stored in the `/var/log` directory on the nodes and can be queried using the `kubectl logs` command or by directly accessing the `/var/log` directory on the nodes***. The Container Engine direct standard output and standard error streams from the containers to a logging driver. This driver is configured to write these container logs in a `JSON` format and store them in the `/var/log` directory at the node level.
- The command `kubectl logs [POD_NAME] --since=3h` is used to restrict the output using time as the criterion.
- ***Any log file older than one day or that has grown to 100 megabytes will be compressed and copied into an archive file***. Only the five most recent archived log files are kept on the node. ***Previous versions are removed in order to avoid logs consuming too much disc space***.
- As the container runs, events happen and the log file grows. Either once per day or when the log file reaches 100 megabytes, whichever comes first, *the log rotate utility creates a new log and compresses the old log file saving it into an archive*. ***It then deletes all but the five most recent compressed log archives***. This ensures that logs don't consume all of the available storage on the node. ***If a container restarts, the default behavior of `kubelet` keeps one terminated container with its logs. If the container is deleted from the node, all the logs are deleted***. If a part is deleted from the node, all corresponding containers are also deleted along with their logs.
- ***GKE installs a logging agent on every node of a cluster, and this agent collects and pushes the containers logs and system component logs to the Stackdriver logging backend***. Stackdriver logging uses FluentD as the node logging agent. *FluentD is a log aggregator that will read all logs, adding helpful metadata and then continuously pushing these logs into Stackdriver logging*. ***FluentD is set up using a daemon set because daemon sets can be used to ensure that every node in a cluster runs a copy of a specific logging pod***. The configuration of the FluentD agent is managed through config maps.
- In Kubernetes, monitoring can be broken into two domains:
  - The ***cluster monitoring*** domain which involves monitoring the cluster level components such as individual nodes, `kube-api` server, `etcd`, and `kube-controller-manager`.
  - The pod monitoring domain which includes the containers and applications that run inside them. It can be divided into several subcategories.
    - ***System specific metrics*** regarding container deployments, instances, health checks and state.
    - ***Containers specific metrics*** such as resource consumption.
    - ***Applications specific metrics*** which are designed by the application developer and exposed to a monitoring solution.
- It's a best practice to apply additional health checks such as ***liveness*** and ***readiness*** probes to Kubernetes-based workloads. ***With a liveness probe, Kubernetes checks to see whether the container is running. If the liveness pro fails and if the restart policy is set to always or on failure, `kubelet` will restart the container***. ***With the readiness probe, Kubernetes checks whether the container is ready to accept requests. If a readiness probe fails, the pods IP addresses removed from all service endpoints by the endpoint controller***.
- Probes can be defined using three types of handlers:
  - ***Command***: With the command probe handler, `kubelet` runs a command inside the container. If the command succeeds, in other words, if it's exit code is zero, the container is considered healthy. Otherwise `kubelet` will kill the container.
  - ***HTTP***: HTTP probe handler uses an HTTP Get request. If the request returns with a code range from 200 to 400, `kubelet` considers the container healthy. Anything outside that range will kill the container.
  - ***TCP***: With the TCP probe handler, `kubelet` attempts to make a TCP connection. If the connection is established, the container is considered healthy.
- The `initialDelaySeconds` field sets the number of seconds to wait before liveness or readiness probes can be initiated. The `periodSeconds` field defines the interval between probe tests. The `timeoutSeconds` field defines the probe timeout and `successThreshold` and `failureThreshold` fields can also be set to define the success and failure thresholds for probes.